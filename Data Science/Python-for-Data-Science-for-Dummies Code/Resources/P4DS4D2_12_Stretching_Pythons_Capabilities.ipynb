{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining applications for data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/developers/<BR>\n",
    "http://scikit-learn.org/stable/faq.html<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(506, 13) y:(506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X, y = boston.data,boston.target\n",
    "print(\"X:%s y:%s\" % (X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "hypothesis = LinearRegression(normalize=True)\n",
    "hypothesis.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.07170557e-01  4.63952195e-02  2.08602395e-02  2.68856140e+00\n",
      " -1.77957587e+01  3.80475246e+00  7.51061703e-04 -1.47575880e+00\n",
      "  3.05655038e-01 -1.23293463e-02 -9.53463555e-01  9.39251272e-03\n",
      " -5.25466633e-01]\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.8972784]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_observation = np.array([1, 0, 1, 0, 0.5, 7, 59, \n",
    "                            6, 3, 200, 20, 350, 4], \n",
    "                           dtype=float).reshape(1, -1)\n",
    "print(hypothesis.predict(new_observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406077428649428"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01116872 0.         0.01979472 0.         0.23662551 0.65893849\n",
      "  0.57775489 0.44288845 0.08695652 0.02480916 0.78723404 0.88173887\n",
      "  0.06263797]]\n"
     ]
    }
   ],
   "source": [
    "#help(LinearRegression)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "print(scaler.transform(new_observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the Hashing Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating the hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2668182151156858128\n"
     ]
    }
   ],
   "source": [
    "print(hash('Python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(abs(hash('Python')) % 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 4, 'for': 1, 'data': 0, 'science': 5, 'machine': 3, 'learning': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "oh_enconder = CountVectorizer()\n",
    "oh_enconded = oh_enconder.fit_transform([\n",
    "'Python for data science','Python for machine learning'])\n",
    "\n",
    "print(oh_enconder.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_1 = 'Python for data science'\n",
    "string_2 = 'Python for machine learning'\n",
    "\n",
    "def hashing_trick(input_string, vector_size=20):\n",
    "    feature_vector = [0] * vector_size\n",
    "    for word in input_string.split(' '):\n",
    "        index = abs(hash(word)) % vector_size\n",
    "        feature_vector[index] = 1\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(hashing_trick(\n",
    "    input_string='Python for data science', \n",
    "    vector_size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(hashing_trick(\n",
    "    input_string='Python for machine learning', \n",
    "    vector_size=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with deterministic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 18)\t1\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "print(csc_matrix([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x20 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.feature_extraction.text as txt\n",
    "htrick = txt.HashingVectorizer(n_features=20, \n",
    "                           binary=True, norm=None)\n",
    "hashed_text = htrick.transform(['Python for data science',\n",
    "                           'Python for machine learning'])\n",
    "hashed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_enconder.transform(['New text has arrived']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htrick.transform(['New text has arrived']).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering Timing and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking with timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.4 ms ± 252 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l = [k for k in range(10**6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 ms ± 45.4 µs per loop (mean ± std. dev. of 5 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 20 -r 5 l = [k for k in range(10**6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 ms ± 347 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "l = list()\n",
    "for k in range(10**6):\n",
    "    l.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as txt\n",
    "htrick = txt.HashingVectorizer(n_features=20, \n",
    "                           binary=True, \n",
    "                           norm=None) \n",
    "oh_enconder = txt.CountVectorizer()\n",
    "texts = ['Python for data science', \n",
    "         'Python for machine learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653 µs ± 4.66 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit oh_enconded = oh_enconder.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 µs ± 448 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hashing = htrick.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010664665180141313\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "cumulative_time = timeit.timeit(\n",
    "    \"hashing = htrick.transform(texts)\", \n",
    "    \"from __main__ import htrick, texts\", \n",
    "    number=10000)\n",
    "print(cumulative_time / 10000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\john\\anaconda3\\lib\\site-packages (0.54.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\john\\anaconda3\\lib\\site-packages (from memory_profiler) (5.4.5)\n"
     ]
    }
   ],
   "source": [
    "# Installation procedures\n",
    "import sys\n",
    "!{sys.executable} -m pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization from IPython (to be repeat at every IPython start)\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 91.91 MiB, increment: 1.31 MiB\n"
     ]
    }
   ],
   "source": [
    "hashing = htrick.transform(texts)\n",
    "%memit dense_hashing = hashing.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example_code.py\n",
    "def comparison_test(text):\n",
    "    import sklearn.feature_extraction.text as txt\n",
    "    htrick = txt.HashingVectorizer(n_features=20, \n",
    "                                   binary=True, \n",
    "                                   norm=None) \n",
    "    oh_enconder = txt.CountVectorizer()\n",
    "    oh_enconded = oh_enconder.fit_transform(text)\n",
    "    hashing = htrick.transform(text)\n",
    "    return oh_enconded, hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from example_code import comparison_test\n",
    "text = ['Python for data science',\n",
    "        'Python for machine learning']\n",
    "%mprun -f comparison_test comparison_test(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running in Parallel on Multiple Cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X, y = digits.data,digits.target\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 s ± 30.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit single_core = cross_val_score(SVC(), X, y, \\\n",
    "                                      cv=20, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44 s ± 44.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit multi_core = cross_val_score(SVC(), X, y, \\\n",
    "                                     cv=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
